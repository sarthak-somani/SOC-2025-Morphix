{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarthak-somani/SOC-2025-Morphix/blob/main/Sarthak_Somani_SOC_Final_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbGA79jJm9z8"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "# app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import os\n",
        "import requests\n",
        "import subprocess\n",
        "import pickle\n",
        "import torch\n",
        "import sys\n",
        "\n",
        "# --- Constants ---\n",
        "STYLEGAN_REPO_DIR = \"stylegan2-ada-pytorch\"\n",
        "# Add the StyleGAN repo to Python's path to find the custom 'torch_utils' module\n",
        "sys.path.append(STYLEGAN_REPO_DIR)\n",
        "\n",
        "MODEL_URL = \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl\"\n",
        "MODEL_PATH = os.path.join(STYLEGAN_REPO_DIR, \"ffhq.pkl\")\n",
        "MORPHIX_REPO_DIR = \"SOC-2025-Morphix\"\n",
        "\n",
        "# --- Page Configuration ---\n",
        "st.set_page_config(\n",
        "    page_title=\"Latent Editor UI\",\n",
        "    page_icon=\"ðŸŽ¨\",\n",
        "    layout=\"wide\",\n",
        ")\n",
        "\n",
        "# --- Helper Functions ---\n",
        "def tensor_to_pil(tensor):\n",
        "    \"\"\"Converts a PyTorch tensor to a PIL Image.\"\"\"\n",
        "    tensor = (tensor.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
        "    return Image.fromarray(tensor[0].cpu().numpy(), 'RGB')\n",
        "\n",
        "def image_to_bytes(img):\n",
        "    \"\"\"Converts a PIL Image to bytes for downloading.\"\"\"\n",
        "    buf = BytesIO()\n",
        "    img.save(buf, format=\"PNG\")\n",
        "    return buf.getvalue()\n",
        "\n",
        "def get_w_from_z(z_latent):\n",
        "    \"\"\"Maps a Z-space latent vector to the W+ space.\"\"\"\n",
        "    G = st.session_state.backend_assets[\"G\"]\n",
        "    device = st.session_state.backend_assets[\"device\"]\n",
        "    z_tensor = torch.from_numpy(z_latent).to(device)\n",
        "    with torch.no_grad():\n",
        "        w_latent = G.mapping(z_tensor, None)\n",
        "    return w_latent\n",
        "\n",
        "def get_image_from_w(w_latent):\n",
        "    \"\"\"Generates a PIL image from a W+ space vector.\"\"\"\n",
        "    G = st.session_state.backend_assets[\"G\"]\n",
        "    with torch.no_grad():\n",
        "        img_tensor = G.synthesis(w_latent, noise_mode='const')\n",
        "    return tensor_to_pil(img_tensor)\n",
        "\n",
        "# --- Backend Loading ---\n",
        "@st.cache_resource\n",
        "def load_backend():\n",
        "    \"\"\"\n",
        "    Clones repositories, downloads the model, and loads all assets into memory.\n",
        "    This function runs only once and its return value is cached.\n",
        "    \"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    if not os.path.exists(STYLEGAN_REPO_DIR):\n",
        "        st.info(\"Cloning StyleGAN2-ADA repository...\")\n",
        "        subprocess.run([\"git\", \"clone\", \"https://github.com/NVlabs/stylegan2-ada-pytorch.git\", STYLEGAN_REPO_DIR], check=True)\n",
        "    if not os.path.exists(MODEL_PATH):\n",
        "        st.info(\"Downloading StyleGAN model (ffhq.pkl)...\")\n",
        "        with requests.get(MODEL_URL, stream=True) as r:\n",
        "            r.raise_for_status()\n",
        "            with open(MODEL_PATH, 'wb') as f:\n",
        "                for chunk in r.iter_content(chunk_size=8192): f.write(chunk)\n",
        "    with open(MODEL_PATH, 'rb') as f:\n",
        "        G = pickle.load(f)['G_ema'].to(device)\n",
        "    st.success(\"âœ… StyleGAN model loaded successfully!\")\n",
        "    if not os.path.exists(MORPHIX_REPO_DIR):\n",
        "        st.info(\"Cloning Morphix repository for latent vectors...\")\n",
        "        subprocess.run([\"git\", \"clone\", \"https://github.com/sarthak-somani/SOC-2025-Morphix.git\", MORPHIX_REPO_DIR], check=True)\n",
        "    try:\n",
        "        vectors = {\n",
        "            'age_w': np.load(os.path.join(MORPHIX_REPO_DIR, 'Models', 'age.npy')),\n",
        "            'smile_w': np.load(os.path.join(MORPHIX_REPO_DIR, 'Models', 'smile.npy')),\n",
        "            'gender_w': np.load(os.path.join(MORPHIX_REPO_DIR, 'Models', 'gender.npy')),\n",
        "            'eyeglasses_w': np.load(os.path.join(MORPHIX_REPO_DIR, 'Models', 'eyeglasses.npy')),\n",
        "        }\n",
        "        st.success(\"âœ… Latent vectors loaded successfully!\")\n",
        "    except FileNotFoundError as e:\n",
        "        st.error(f\"Error loading latent vectors: {e}\")\n",
        "        return None\n",
        "    return {\n",
        "        \"G\": G, \"device\": device,\n",
        "        **{k: torch.from_numpy(v).to(device) for k, v in vectors.items()}\n",
        "    }\n",
        "\n",
        "# --- State Management for Undo/Redo ---\n",
        "def capture_state():\n",
        "    \"\"\"Captures the current editable state, which is now the w_latent vector.\"\"\"\n",
        "    return {\"w_latent\": st.session_state.w_latent.clone()}\n",
        "\n",
        "def load_state(state):\n",
        "    \"\"\"Loads a state dictionary back into the session.\"\"\"\n",
        "    st.session_state.w_latent = state[\"w_latent\"]\n",
        "\n",
        "# --- Image Generation ---\n",
        "def generate_image_and_update_state():\n",
        "    \"\"\"Generates an image from the current w_latent and applies all edits.\"\"\"\n",
        "    assets = st.session_state.backend_assets\n",
        "    w_base = st.session_state.w_latent\n",
        "\n",
        "    # Apply edits from sliders and presets\n",
        "    w_edited = w_base + \\\n",
        "               assets['age_w'] * st.session_state.age_strength + \\\n",
        "               assets['smile_w'] * st.session_state.smile_strength + \\\n",
        "               assets['gender_w'] * st.session_state.gender_strength + \\\n",
        "               assets['eyeglasses_w'] * st.session_state.eyeglasses_strength\n",
        "\n",
        "    st.session_state.image = get_image_from_w(w_edited)\n",
        "\n",
        "# --- Session State Initialization ---\n",
        "if 'backend_assets' not in st.session_state:\n",
        "    with st.spinner(\"ðŸš€ Starting up... Loading models and assets...\"):\n",
        "        st.session_state.backend_assets = load_backend()\n",
        "\n",
        "if 'image' not in st.session_state and st.session_state.backend_assets:\n",
        "    G = st.session_state.backend_assets[\"G\"]\n",
        "    # Main state variables\n",
        "    st.session_state.z_latent = np.random.randn(1, G.z_dim)\n",
        "    st.session_state.w_latent = get_w_from_z(st.session_state.z_latent)\n",
        "    st.session_state.age_strength = 0.0\n",
        "    st.session_state.smile_strength = 0.0\n",
        "    st.session_state.gender_strength = 0.0\n",
        "    st.session_state.eyeglasses_strength = 0.0\n",
        "\n",
        "    # Style Mixing state variables\n",
        "    st.session_state.source_a_z = np.random.randn(1, G.z_dim)\n",
        "    st.session_state.source_b_z = np.random.randn(1, G.z_dim)\n",
        "    st.session_state.source_a_img = get_image_from_w(get_w_from_z(st.session_state.source_a_z))\n",
        "    st.session_state.source_b_img = get_image_from_w(get_w_from_z(st.session_state.source_b_z))\n",
        "\n",
        "    # History for undo/redo\n",
        "    st.session_state.undo_stack = []\n",
        "    st.session_state.redo_stack = []\n",
        "\n",
        "    generate_image_and_update_state()\n",
        "\n",
        "# --- Callbacks ---\n",
        "def record_undo():\n",
        "    st.session_state.undo_stack.append(capture_state())\n",
        "    st.session_state.redo_stack.clear()\n",
        "\n",
        "def random_face_callback():\n",
        "    record_undo()\n",
        "    G = st.session_state.backend_assets[\"G\"]\n",
        "    st.session_state.z_latent = np.random.randn(1, G.z_dim)\n",
        "    st.session_state.w_latent = get_w_from_z(st.session_state.z_latent)\n",
        "    reset_all_callback(record_history=False) # Reset sliders but don't create a second undo state\n",
        "\n",
        "def reset_all_callback(record_history=True):\n",
        "    if record_history: record_undo()\n",
        "    st.session_state.age_strength = 0.0\n",
        "    st.session_state.smile_strength = 0.0\n",
        "    st.session_state.gender_strength = 0.0\n",
        "    st.session_state.eyeglasses_strength = 0.0\n",
        "    generate_image_and_update_state()\n",
        "\n",
        "def toggle_eyeglasses_callback():\n",
        "    record_undo()\n",
        "    st.session_state.eyeglasses_strength = 3.5 if st.session_state.eyeglasses_strength == 0.0 else 0.0\n",
        "    generate_image_and_update_state()\n",
        "\n",
        "def undo_callback():\n",
        "    if st.session_state.undo_stack:\n",
        "        st.session_state.redo_stack.append(capture_state())\n",
        "        load_state(st.session_state.undo_stack.pop())\n",
        "        generate_image_and_update_state()\n",
        "\n",
        "def redo_callback():\n",
        "    if st.session_state.redo_stack:\n",
        "        st.session_state.undo_stack.append(capture_state())\n",
        "        load_state(st.session_state.redo_stack.pop())\n",
        "        generate_image_and_update_state()\n",
        "\n",
        "def new_source_face_callback(source_key):\n",
        "    G = st.session_state.backend_assets[\"G\"]\n",
        "    z = np.random.randn(1, G.z_dim)\n",
        "    w = get_w_from_z(z)\n",
        "    img = get_image_from_w(w)\n",
        "    st.session_state[f'source_{source_key}_z'] = z\n",
        "    st.session_state[f'source_{source_key}_img'] = img\n",
        "\n",
        "def apply_style_mix_callback(crossover):\n",
        "    record_undo()\n",
        "    w_a = get_w_from_z(st.session_state.source_a_z)\n",
        "    w_b = get_w_from_z(st.session_state.source_b_z)\n",
        "    w_mixed = w_a.clone()\n",
        "    w_mixed[:, crossover:, :] = w_b[:, crossover:, :]\n",
        "    st.session_state.w_latent = w_mixed\n",
        "    reset_all_callback(record_history=False) # Reset sliders to show the pure mix\n",
        "\n",
        "# --- UI Layout ---\n",
        "st.title(\"ðŸŽ¨ Real-Time Latent Editing Interface\")\n",
        "\n",
        "if not st.session_state.backend_assets or 'image' not in st.session_state:\n",
        "    st.error(\"Application failed to initialize. Please check logs or restart.\")\n",
        "else:\n",
        "    with st.sidebar:\n",
        "        st.header(\"Main Controls\")\n",
        "\n",
        "        # Undo/Redo\n",
        "        undo_disabled = not st.session_state.undo_stack\n",
        "        redo_disabled = not st.session_state.redo_stack\n",
        "        col1, col2 = st.columns(2)\n",
        "        with col1: st.button(\"Undo\", on_click=undo_callback, disabled=undo_disabled, use_container_width=True)\n",
        "        with col2: st.button(\"Redo\", on_click=redo_callback, disabled=redo_disabled, use_container_width=True)\n",
        "\n",
        "        st.button(\"New Random Face\", on_click=random_face_callback, use_container_width=True)\n",
        "        st.button(\"Reset All Edits\", on_click=reset_all_callback, use_container_width=True)\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.header(\"Attribute Sliders\")\n",
        "        st.slider(\"Age\", -5.0, 5.0, key=\"age_strength\", on_change=generate_image_and_update_state)\n",
        "        st.slider(\"Smile\", -5.0, 5.0, key=\"smile_strength\", on_change=generate_image_and_update_state)\n",
        "        st.slider(\"Gender\", -5.0, 5.0, key=\"gender_strength\", on_change=generate_image_and_update_state)\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.header(\"Presets\")\n",
        "        btn_text = \"Remove Eyeglasses\" if st.session_state.eyeglasses_strength != 0.0 else \"Add Eyeglasses\"\n",
        "        st.button(btn_text, on_click=toggle_eyeglasses_callback, use_container_width=True)\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.header(\"Style Mixing\")\n",
        "        col1, col2 = st.columns(2)\n",
        "        with col1:\n",
        "            st.image(st.session_state.source_a_img, caption=\"Source A\")\n",
        "            st.button(\"New Face A\", on_click=new_source_face_callback, args=('a',), use_container_width=True)\n",
        "        with col2:\n",
        "            st.image(st.session_state.source_b_img, caption=\"Source B\")\n",
        "            st.button(\"New Face B\", on_click=new_source_face_callback, args=('b',), use_container_width=True)\n",
        "\n",
        "        crossover = st.slider(\"Mixing Crossover Point\", 0, 18, 8, help=\"0-3: Coarse styles (pose, shape). 4-7: Middle styles (facial features). 8-18: Fine styles (color, texture).\")\n",
        "        st.button(\"Apply Style Mix\", on_click=apply_style_mix_callback, args=(crossover,), use_container_width=True)\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.download_button(label=\"ðŸ’¾ Save Image\", data=image_to_bytes(st.session_state.image), file_name=\"generated_face.png\", mime=\"image/png\", use_container_width=True)\n",
        "\n",
        "    st.image(st.session_state.image, caption=\"Generated by the Backend\", use_column_width=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVl_GEM9HxNm"
      },
      "outputs": [],
      "source": [
        "!curl ipecho.net/plain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3il0CUQRHyVa"
      },
      "outputs": [],
      "source": [
        "# Step 1: Install all necessary packages quietly\n",
        "!pip install -q streamlit numpy torch requests Pillow\n",
        "\n",
        "# Step 2: Run the Streamlit app in the background on a fixed port (8501)\n",
        "!streamlit run app.py --server.port 8501 &>/dev/null&\n",
        "\n",
        "# Step 3: Wait a few seconds for the app to start up\n",
        "import time\n",
        "time.sleep(10)\n",
        "\n",
        "# Step 4: Use localtunnel to expose the correct port\n",
        "!npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOltNKxJqAk+3p+xQnI+fTk",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.13.0)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
